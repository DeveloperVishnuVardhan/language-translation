{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "a = torch.randn(4)\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = torch.randn(3)\n",
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.3014,  0.7692, -0.2933,  0.4622])\n",
      "tensor([-0.3266, -0.5133, -1.2151])\n"
     ]
    }
   ],
   "source": [
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = a.unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 3])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(a * b).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([350, 512])\n",
      "torch.Size([350, 1])\n",
      "torch.Size([256])\n",
      "torch.Size([350, 256])\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "import math\n",
    "class PositionalEncodinds(nn.Module):\n",
    "    def __init__(self, vocab_size: int, embedding_dim: int, dropout: float):\n",
    "        \"\"\"Creates Postional encodings to add to the output of\n",
    "        Embedding layer.\n",
    "\n",
    "        Args:\n",
    "            vocab_size (int): Total number of words in the vocabulary.\n",
    "            embedding_dim (int): Dimension of Embedding.\n",
    "            dropout (float): dropout rate to apply.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        # Create a tensor for positional encoding.\n",
    "        pos_encoding = torch.zeros(vocab_size, embedding_dim)\n",
    "        print(pos_encoding.shape)\n",
    "        pos = torch.arange(0, vocab_size).unsqueeze(1)  # Numerator term.\n",
    "        print(pos.shape)\n",
    "        # Denominator: pow(10000, 2i / d_model) == 1 / \n",
    "        # torch.exp(-math.log(1000.0) / d_model) * 2i)\n",
    "        denom_term = torch.exp(-(math.log(1000.0) / embedding_dim) * torch.arange(0, embedding_dim, 2))\n",
    "        print(denom_term.shape)\n",
    "        print((pos * denom_term).shape)\n",
    "\n",
    "ob = PositionalEncodinds(350, 512, 0.1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
